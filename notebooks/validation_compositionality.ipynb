{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fiscal-assessment",
   "metadata": {},
   "source": [
    "# Compositionality with validation primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "import admath.utils as utils\n",
    "\n",
    "env, encoder, decoder = utils.load_env(\n",
    "    '/SymbolicMathematics', \n",
    "    '/fwd_bwd_ibp.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-techno",
   "metadata": {},
   "source": [
    "#### Collect short examples from the validation set\n",
    "\n",
    "More specifically, those examples which do not have the operations in `exclude` and are of length <= 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = {\n",
    "   ' I ', 'asin', 'acos', 'atan', 'sinh', 'cosh', 'tanh', 'asinh', 'acosh', 'atanh'\n",
    "}\n",
    "\n",
    "ds = open('/prim_fwd.valid').readlines()\n",
    "ds_ = []\n",
    "for d in tqdm(ds, total=len(ds)):\n",
    "    temp = d.strip().split('|')\n",
    "    assert len(temp) == 2\n",
    "    temp = temp[1].split('\\t')\n",
    "    assert len(temp) == 2\n",
    "    x, y = temp\n",
    "    \n",
    "    skip = False\n",
    "    for op in exclude:\n",
    "        if op in x:\n",
    "            skip = True\n",
    "        if op in y:\n",
    "            skip = True\n",
    "    \n",
    "    if skip:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        x_prefix = env.clean_prefix(x.replace(\"sub Y' \", '').split())\n",
    "        y_prefix = env.clean_prefix(y.replace(\"sub Y' \", '').split())\n",
    "\n",
    "        x = env.infix_to_sympy(env.prefix_to_infix(x_prefix))\n",
    "        if len(str(x)) <= 20:\n",
    "            ds_.append({\n",
    "                'x': x,\n",
    "                'y': env.prefix_to_infix(y_prefix),\n",
    "            })\n",
    "    except:\n",
    "        pass\n",
    "ds = ds_\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-interference",
   "metadata": {},
   "source": [
    "### Run examples, then choose ones that succeeded as primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 50\n",
    "beam_size = 50\n",
    "N = 1000\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_result(out, problems):\n",
    "    nc = len([x for x in out if x['correct']])\n",
    "    ncancelled = len([x for x in out if x['cancelled']])\n",
    "    nc_notcancelled = len([x for x in out if x['correct'] and not x['cancelled']])\n",
    "    n = len(out)\n",
    "    return {\n",
    "        'n': n,\n",
    "        'accuracy': nc/n,\n",
    "        'length': np.mean([len(str(x['x'])) for x in problems]),\n",
    "        'top_n': top_n,\n",
    "        'cancelled': ncancelled/n,\n",
    "        'nc_notcancelled': nc_notcancelled/n\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from admath.utils import run_and_check\n",
    "\n",
    "problems = random.sample(ds, N)\n",
    "out = run_and_check(problems, env, encoder, decoder, torch.device('cuda'), top_n, seconds=10, beam_size=beam_size)\n",
    "\n",
    "parse_result(out, problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "primitives = [x for x in out if x['correct']]\n",
    "len(primitives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-program",
   "metadata": {},
   "source": [
    "#### Compositionality 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "from admath.compositionality import random_tuples\n",
    "\n",
    "lst = list(range(len(primitives)))\n",
    "\n",
    "problems = []\n",
    "for idxs in random_tuples(lst, 2, N):\n",
    "    problems.append(\n",
    "        {'x': primitives[idxs[0]]['x'] + primitives[idxs[1]]['x']}\n",
    "    )\n",
    "\n",
    "out = run_and_check(problems, env, encoder, decoder, torch.device('cuda'), top_n, seconds=10, beam_size=beam_size)\n",
    "\n",
    "results['comp_2'] = parse_result(out, problems)\n",
    "print(results['comp_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-asbestos",
   "metadata": {},
   "source": [
    "#### Compositionality 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = []\n",
    "\n",
    "lst = list(range(len(primitives)))\n",
    "\n",
    "problems = []\n",
    "for idxs in random_tuples(lst, 3, N):\n",
    "    problems.append(\n",
    "        {'x': primitives[idxs[0]]['x'] + \n",
    "         primitives[idxs[1]]['x'] + \n",
    "         primitives[idxs[2]]['x']}\n",
    "    )\n",
    "\n",
    "out = run_and_check(problems, env, encoder, decoder, torch.device('cuda'), top_n, seconds=10, beam_size=beam_size)\n",
    "\n",
    "results['comp_3'] = parse_result(out, problems)\n",
    "print(results['comp_3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-talent",
   "metadata": {},
   "source": [
    "#### Compositionality 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = []\n",
    "\n",
    "lst = list(range(len(primitives)))\n",
    "\n",
    "problems = []\n",
    "for idxs in random_tuples(lst, 4, N):\n",
    "    problems.append(\n",
    "        {'x': primitives[idxs[0]]['x'] + \n",
    "         primitives[idxs[1]]['x'] + \n",
    "         primitives[idxs[2]]['x'] +\n",
    "         primitives[idxs[3]]['x']}\n",
    "    )\n",
    "\n",
    "out = run_and_check(problems, env, encoder, decoder, torch.device('cuda'), top_n, seconds=10, beam_size=beam_size)\n",
    "\n",
    "results['comp_4'] = parse_result(out, problems)\n",
    "print(results['comp_4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-breed",
   "metadata": {},
   "source": [
    "#### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../output/validation_compositionality_top%d.json' % top_n, 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-compromise",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
